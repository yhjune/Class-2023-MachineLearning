{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPmL3V8qP0NncTNHvjjPgYa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"zRPbCgV0yOxS"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["cd /content/drive/MyDrive/GitHub/Website-Fingerprinting/Random-Forest"],"metadata":{"id":"EO8ITcD2ydVd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pwd"],"metadata":{"id":"I9cmWM72yes8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","import numpy as np\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.decomposition import PCA\n","from scipy.spatial.distance import pdist, squareform\n","\n","\n","\n","with open('mon2.pkl', 'rb') as file:\n","    df2 = pickle.load(file)\n","\n","#whole data\n","X = df2[['total_income', 'total_outcome', 'packet_num', 'outgoing_ratio', 'incoming_ratio', 'duration','duration_per_packet','time_mean','time_std','time_var', 'size_mean', 'size_std','size_var','cumlative_mean','cumlative_var','burst_mean','burst_std','burst_var']]\n","y = df2['label']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n","\n","rf_model = RandomForestClassifier(max_depth=20, n_estimators=100,random_state=42, class_weight='balanced')\n","rf_model.fit(X_train, y_train)\n","\n","predictions = rf_model.predict(X_test)\n"],"metadata":{"id":"9Bz3VWvJyf9d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#metrics\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","accuracy = accuracy_score(y_test, predictions)\n","precision = precision_score(y_test, predictions, average='weighted')\n","recall = recall_score(y_test, predictions, average='weighted')\n","f1 = f1_score(y_test, predictions, average='weighted')\n","\n","print(\"<closed_multi>\")\n","print(f'정확도: {accuracy:.2f}')\n","print(f'정밀도: {precision:.2f}')\n","print(f'재현율: {recall:.2f}')\n","from sklearn.metrics import confusion_matrix\n","cm = confusion_matrix(y_test, predictions)\n","print(cm)"],"metadata":{"id":"Vr1XzOsnyhJu"},"execution_count":null,"outputs":[]}]}